{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision: Final Project\n",
    "\n",
    "Submitted by: [ **Andrey Gresko, 334041076 | Amit Levy, 307928010** ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners = 300, qualityLevel = 0.1, minDistance = 2, blockSize = 7)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize = (15,15), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The video feed is read in as a VideoCapture object\n",
    "cap = cv2.VideoCapture(\"maze.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for color to draw optical flow track\n",
    "color = 255 # white \n",
    "ret, first_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an image filled with zero intensities with the same dimensions as the frame - for later drawing purposes\n",
    "mask = np.zeros_like(prev_gray)\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # total frame amount\n",
    "frame_cnt = 0\n",
    "\n",
    "while (cap.isOpened() and frame_cnt < length - 25): # -25 frames because video has ~0.5 fade out in the end\n",
    "    # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None or ret == False:\n",
    "        break\n",
    "    frame_cnt += 1\n",
    "    enter_flag = True\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    next, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev, None, **lk_params)\n",
    "    # Selects good feature points for previous position\n",
    "    good_old = prev[status == 1]\n",
    "    # Selects good feature points for next position\n",
    "    good_new = next[status == 1]\n",
    "    # Draws the optical flow tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        # Returns a contiguous flattened array as (x, y) coordinates for new point\n",
    "        a, b = new.ravel()\n",
    "        # Returns a contiguous flattened array as (x, y) coordinates for old point\n",
    "        c, d = old.ravel()\n",
    "        speed_vector = np.sqrt((a - c)**2 + (b - d)**2)\n",
    "        if speed_vector > 1:\n",
    "            enter_flag = False\n",
    "            # Draws filled circle (thickness of -1) at new position with green color and radius of 3\n",
    "            cv2.circle(mask, (a, b), 1, color, -1)\n",
    "    if enter_flag == True: # draw path if the points were bad (refresh points to track)\n",
    "        prev = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
    "    else:\n",
    "        prev = good_new.reshape(-1, 1, 2)\n",
    "    # Overlays the optical flow tracks on the original frame\n",
    "    mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    mask_bgr = cv2.GaussianBlur(mask_bgr, (0,0), 3)\n",
    "    mask_bgr = cv2.applyColorMap(mask_bgr, cv2.COLORMAP_HOT)\n",
    "    output = cv2.add(frame, mask_bgr)\n",
    "    cv2.imwrite(\"./heat_map.jpg\", mask_bgr) # save heat map as an image\n",
    "    cv2.imshow('Heat Map', mask_bgr) # show heat map video stream\n",
    "    cv2.imwrite(\"./opt_flow_hotpath.jpg\", output) # save motion path as an image\n",
    "    cv2.imshow(\"Optical Flow\", output) # show motion path\n",
    "    prev_gray = gray\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# The following frees up resources and closes all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
